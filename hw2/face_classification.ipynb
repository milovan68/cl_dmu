{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, models, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_model_classification(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_model_classification, self).__init__()\n",
    "        \"\"\"\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=(5,5))\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=(5,5))\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.conv2_drop = nn.Dropout2d(p = 0.3)\n",
    "        self.conv3_drop = nn.Dropout2d(p = 0.5)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=(3,3))\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.conv4 = nn.Conv2d(128, 256, kernel_size=(3,3))\n",
    "        self.bn4 = nn.BatchNorm2d(256)\n",
    "        self.conv5 = nn.Conv2d(256, 512, kernel_size=(3,3))\n",
    "        self.bn5 = nn.BatchNorm2d(512)\n",
    "        self.conv6 = nn.Conv2d(512, 1024, kernel_size=(1,1))\n",
    "        self.bn6 = nn.BatchNorm2d(1024)\n",
    "        self.fc1 = nn.Linear(4096, 2300)\n",
    "        \"\"\"\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=12, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "\n",
    "        self.conv2 = nn.Conv2d(in_channels=12, out_channels=12, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu2 = nn.ReLU()\n",
    "\n",
    "        self.pool_1 = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(in_channels=12, out_channels=24, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        \n",
    "        self.conv5 = nn.Conv2d(in_channels=24, out_channels=48, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu5 = nn.ReLU()\n",
    "\n",
    "        self.conv6 = nn.Conv2d(in_channels=48, out_channels=96, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu6 = nn.ReLU()\n",
    "\n",
    "        self.pool_2 = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "        self.conv7 = nn.Conv2d(in_channels=96, out_channels=186, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu7 = nn.ReLU()\n",
    "\n",
    "        self.conv8 = nn.Conv2d(in_channels=186, out_channels=196, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu8 = nn.ReLU()\n",
    "\n",
    "        self.fc = nn.Linear(in_features=8 * 8 * 196, out_features=2300)\n",
    "\n",
    "    def forward(self, input):\n",
    "        output = self.conv1(input)\n",
    "        output = self.relu1(output)\n",
    "\n",
    "        output = self.conv2(output)\n",
    "        output = self.relu2(output)\n",
    "\n",
    "        output = self.pool_1(output)\n",
    "\n",
    "        output = self.conv3(output)\n",
    "        output = self.relu3(output)\n",
    "        \n",
    "        output = self.conv5(output)\n",
    "        output = self.relu5(output)\n",
    "\n",
    "        output = self.conv6(output)\n",
    "        output = self.relu6(output)\n",
    "\n",
    "        output = self.pool_2(output)\n",
    "\n",
    "        output = self.conv7(output)\n",
    "        output = self.relu7(output)\n",
    "\n",
    "        output = self.conv8(output)\n",
    "        output = self.relu8(output)\n",
    "\n",
    "        output = output.view(-1, 8 * 8 * 196)\n",
    "\n",
    "        output = self.fc(output)\n",
    "        output = F.log_softmax(output, dim=1)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, channel_size, stride=1):\n",
    "        super(ResBlock, self).__init__()\n",
    "        self.block = nn.Sequential(nn.Conv2d(in_channels=channel_size, out_channels=channel_size, \n",
    "                                             kernel_size=3, stride=stride, padding=1, bias=False),\n",
    "                                   nn.BatchNorm2d(num_features=channel_size),\n",
    "                                   nn.ReLU(inplace=True),\n",
    "                                   nn.Conv2d(in_channels=channel_size, out_channels=channel_size, \n",
    "                                             kernel_size=3, stride=stride, padding=1, bias=False),\n",
    "                                   nn.BatchNorm2d(num_features=channel_size))\n",
    "        self.logit_non_linear = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = x\n",
    "        output = self.block(output)\n",
    "        output = self.logit_non_linear(output + x)\n",
    "        return output\n",
    "class Network(nn.Module):\n",
    "    def __init__(self, num_feats, hidden_sizes, num_classes, feat_dim=10):\n",
    "        super(Network, self).__init__()\n",
    "        \n",
    "        self.hidden_sizes = [num_feats] + hidden_sizes + [num_classes]\n",
    "        \n",
    "        self.layers = []\n",
    "        for idx, channel_size in enumerate(hidden_sizes):\n",
    "            self.layers.append(nn.Conv2d(in_channels=self.hidden_sizes[idx], \n",
    "                                         out_channels=self.hidden_sizes[idx+1], \n",
    "                                         kernel_size=3, stride=2, bias=False))\n",
    "            self.layers.append(nn.ReLU(inplace=True))\n",
    "            self.layers.append(ResBlock(channel_size=channel_size))\n",
    "            \n",
    "        self.layers = nn.Sequential(*self.layers)\n",
    "        self.linear_label = nn.Linear(self.hidden_sizes[-2], self.hidden_sizes[-1], bias=False)\n",
    "        \n",
    "        # For creating the embedding to be passed into the Center Loss criterion\n",
    "        self.linear_closs = nn.Linear(self.hidden_sizes[-2], feat_dim, bias=False)\n",
    "        self.relu_closs = nn.ReLU(inplace=True)\n",
    "    \n",
    "    def forward(self, x, evalMode=False):\n",
    "        output = x\n",
    "        output = self.layers(output)\n",
    "            \n",
    "        output = F.avg_pool2d(output, [output.size(2), output.size(3)], stride=1)\n",
    "        output = output.reshape(output.shape[0], output.shape[1])\n",
    "        \n",
    "        label_output = self.linear_label(output)\n",
    "        label_output = label_output/torch.norm(self.linear_label.weight, dim=1)\n",
    "        \n",
    "        # Create the feature embedding for the Center Loss\n",
    "        closs_output = self.linear_closs(output)\n",
    "        closs_output = self.relu_closs(closs_output)\n",
    "\n",
    "        return closs_output, label_output\n",
    "\n",
    "def init_weights(m):\n",
    "    if type(m) == nn.Conv2d or type(m) == nn.Linear:\n",
    "        torch.nn.init.xavier_normal_(m.weight.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Unit(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(Unit, self).__init__()\n",
    "\n",
    "        self.conv = nn.Conv2d(in_channels=in_channels, kernel_size=3, out_channels=out_channels, stride=1, padding=1)\n",
    "        self.bn = nn.BatchNorm2d(num_features=out_channels)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, input):\n",
    "        output = self.conv(input)\n",
    "        output = self.bn(output)\n",
    "        output = self.relu(output)\n",
    "\n",
    "        return output\n",
    "\n",
    "class CNNet(nn.Module):\n",
    "    def __init__(self, num_class):\n",
    "        super(CNNet, self).__init__()\n",
    "\n",
    "        # Create 14 layers of the unit with max pooling in between\n",
    "        self.unit1 = Unit(in_channels=3, out_channels=32)\n",
    "        self.unit2 = Unit(in_channels=32, out_channels=32)\n",
    "        self.unit3 = Unit(in_channels=32, out_channels=32)\n",
    "\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "        self.unit4 = Unit(in_channels=32, out_channels=64)\n",
    "        self.unit5 = Unit(in_channels=64, out_channels=64)\n",
    "        self.unit6 = Unit(in_channels=64, out_channels=64)\n",
    "        self.unit7 = Unit(in_channels=64, out_channels=64)\n",
    "\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "        self.unit8 = Unit(in_channels=64, out_channels=128)\n",
    "        self.unit9 = Unit(in_channels=128, out_channels=128)\n",
    "        self.unit10 = Unit(in_channels=128, out_channels=128)\n",
    "        self.unit11 = Unit(in_channels=128, out_channels=128)\n",
    "\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "        self.unit12 = Unit(in_channels=128, out_channels=128)\n",
    "        self.unit13 = Unit(in_channels=128, out_channels=128)\n",
    "        self.unit14 = Unit(in_channels=128, out_channels=128)\n",
    "\n",
    "        self.avgpool = nn.AvgPool2d(kernel_size=4)\n",
    "\n",
    "        # Add all the units into the Sequential layer in exact order\n",
    "        self.net = nn.Sequential(self.unit1, self.unit2, self.unit3, self.pool1, self.unit4, self.unit5, self.unit6\n",
    "                                 , self.unit7, self.pool2, self.unit8, self.unit9, self.unit10, self.unit11, self.pool3,\n",
    "                                 self.unit12, self.unit13, self.unit14, self.avgpool)\n",
    "\n",
    "        self.fc = nn.Linear(in_features=128, out_features=num_class)\n",
    "\n",
    "    def forward(self, input):\n",
    "        output = self.net(input)\n",
    "        output = output.view(-1, 128)\n",
    "        output = self.fc(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_datasets = {}\n",
    "dataloaders_dict ={}\n",
    "data_transforms = {\n",
    "            'train': transforms.Compose([\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                #transforms.RandomResizedCrop(32),\n",
    "                transforms.ToTensor(),\n",
    "                #transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "                transforms.Normalize([0.44, 0.28, 0.37], [0.26, 0.18, 0.24])\n",
    "            ]),\n",
    "            'val': transforms.Compose([\n",
    "                #transforms.Resize(32),\n",
    "                #transforms.CenterCrop(32),\n",
    "                transforms.ToTensor(),\n",
    "                #transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "                transforms.Normalize([0.44, 0.28, 0.37], [0.26, 0.18, 0.24])\n",
    "            ]),\n",
    "        }\n",
    "image_datasets['train'] = datasets.ImageFolder('/home/d.milovanov/win_kaggle/hw3/medium/', data_transforms['train'])\n",
    "image_datasets['val'] = datasets.ImageFolder('/home/d.milovanov/win_kaggle/hw3/validation_classification/',\n",
    "                                             data_transforms['val'])\n",
    "dataloaders_dict['train'] = torch.utils.data.DataLoader(image_datasets['train'],batch_size=128, shuffle=True)\n",
    "dataloaders_dict['val'] = torch.utils.data.DataLoader(image_datasets['val'],batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_sizes = [256, 512, 1024, 2048]\n",
    "num_feats = 3\n",
    "num_classes = 2300\n",
    "\n",
    "#model = CNNet(num_classes)\n",
    "cuda = torch.cuda.is_available()\n",
    "model = Network(num_feats, hidden_sizes, num_classes)\n",
    "model.apply(init_weights)\n",
    "#model = Net()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=0.0001)\n",
    "optimizer = torch.optim.SGD(model.parameters(), \n",
    "                            lr=1e-2, \n",
    "                            #weight_decay=5e-5,\n",
    "                            weight_decay=5e-4,\n",
    "                            momentum=0.9)\n",
    "device = torch.device(\"cuda\" if cuda else \"cpu\")\n",
    "def train_model(model, train_loader, criterion, optimizer):\n",
    "    model.train()\n",
    "    model.to(device)\n",
    "    running_loss = 0.0\n",
    "    start_time = time.time()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):     \n",
    "        optimizer.zero_grad()\n",
    "        data = data.float()\n",
    "        data = data.to(device)\n",
    "        target = target.long().to(device)\n",
    "\n",
    "        outputs = model(data)[1]\n",
    "    \n",
    "        loss = criterion(outputs, target)\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    end_time = time.time()\n",
    "\n",
    "    running_loss /= len(train_loader)\n",
    "    print('Training Loss: ', running_loss, 'Time: ',end_time - start_time, 's')\n",
    "    return running_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, test_loader, criterion):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        model.to(device)\n",
    "\n",
    "        running_loss = 0.0\n",
    "        total_predictions = 0.0\n",
    "        correct_predictions = 0.0\n",
    "\n",
    "        for batch_idx, (data, target) in enumerate(test_loader):\n",
    "            data = data.float()\n",
    "            data = data.to(device)\n",
    "            target = target.long().to(device)\n",
    "\n",
    "            outputs = model(data)[1]\n",
    "            \n",
    "\n",
    "            _, predicted = torch.max(F.softmax(outputs, dim=1), 1)\n",
    "            total_predictions += target.size(0)\n",
    "            correct_predictions += (predicted == target).sum().item()\n",
    "\n",
    "            loss = criterion(outputs, target).detach()\n",
    "            running_loss += loss.item()\n",
    "        running_loss /= len(test_loader)\n",
    "        acc = (correct_predictions/total_predictions)*100.0\n",
    "        print('Testing Loss: ', running_loss)\n",
    "        print('Testing Accuracy: ', acc, '%')\n",
    "        return running_loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================0/100 epoch=============\n",
      "Training Loss:  5.011818241471817 Time:  2903.111112833023 s\n",
      "Testing Loss:  3.717221584584978\n",
      "Testing Accuracy:  26.211693110193433 %\n",
      "====================\n",
      "==================1/100 epoch=============\n",
      "Training Loss:  3.017333748925519 Time:  2902.2039868831635 s\n",
      "Testing Loss:  2.642170230547587\n",
      "Testing Accuracy:  44.7294066507281 %\n",
      "====================\n",
      "==================2/100 epoch=============\n",
      "Training Loss:  2.2844844922553262 Time:  2904.4578261375427 s\n",
      "Testing Loss:  2.2464216815100775\n",
      "Testing Accuracy:  52.35818300369485 %\n",
      "====================\n",
      "==================3/100 epoch=============\n",
      "Training Loss:  1.9038356153264289 Time:  2912.5522191524506 s\n",
      "Testing Loss:  1.9915782511234283\n",
      "Testing Accuracy:  58.20473810041295 %\n",
      "====================\n",
      "==================4/100 epoch=============\n",
      "Training Loss:  1.6751337393765728 Time:  2904.8406682014465 s\n",
      "Testing Loss:  1.8156611257129245\n",
      "Testing Accuracy:  61.44316452945012 %\n",
      "====================\n",
      "==================5/100 epoch=============\n",
      "Training Loss:  1.5153164523067986 Time:  2904.8722858428955 s\n",
      "Testing Loss:  1.774281620979309\n",
      "Testing Accuracy:  61.42143012388611 %\n",
      "====================\n",
      "==================6/100 epoch=============\n",
      "Training Loss:  1.3993486094742011 Time:  2903.9404439926147 s\n",
      "Testing Loss:  1.769388539923562\n",
      "Testing Accuracy:  61.48663334057814 %\n",
      "====================\n",
      "==================7/100 epoch=============\n",
      "Training Loss:  1.3037081196774285 Time:  2904.2725825309753 s\n",
      "Testing Loss:  1.6547863682111104\n",
      "Testing Accuracy:  64.11649641382307 %\n",
      "====================\n",
      "==================8/100 epoch=============\n",
      "Training Loss:  1.2292914104602701 Time:  2904.9598808288574 s\n",
      "Testing Loss:  1.7051246464252472\n",
      "Testing Accuracy:  62.96457291893067 %\n",
      "====================\n",
      "==================9/100 epoch=============\n",
      "Training Loss:  1.1644038331426987 Time:  2905.080360174179 s\n",
      "Testing Loss:  1.5850624673896365\n",
      "Testing Accuracy:  65.2466855031515 %\n",
      "====================\n",
      "==================10/100 epoch=============\n",
      "Training Loss:  1.1143544290265808 Time:  2905.290212392807 s\n",
      "Testing Loss:  1.5169188910060458\n",
      "Testing Accuracy:  66.55074983699197 %\n",
      "====================\n",
      "==================11/100 epoch=============\n",
      "Training Loss:  1.0677014065078305 Time:  2905.055810213089 s\n",
      "Testing Loss:  1.4732816848489974\n",
      "Testing Accuracy:  67.96348619865246 %\n",
      "====================\n",
      "==================12/100 epoch=============\n",
      "Training Loss:  1.0288798678411197 Time:  2903.1395003795624 s\n",
      "Testing Loss:  1.3993925485346053\n",
      "Testing Accuracy:  69.91958269941317 %\n",
      "====================\n",
      "==================13/100 epoch=============\n",
      "Training Loss:  0.9929432262843974 Time:  2905.2170794010162 s\n",
      "Testing Loss:  1.419227917989095\n",
      "Testing Accuracy:  69.48489458813302 %\n",
      "====================\n",
      "==================14/100 epoch=============\n",
      "Training Loss:  0.9644386072551476 Time:  2905.16241812706 s\n",
      "Testing Loss:  1.4038994742764368\n",
      "Testing Accuracy:  69.33275374918496 %\n",
      "====================\n",
      "==================15/100 epoch=============\n",
      "Training Loss:  0.9352802386737034 Time:  2904.842081785202 s\n",
      "Testing Loss:  1.4348399341106415\n",
      "Testing Accuracy:  68.5937839600087 %\n",
      "====================\n",
      "==================16/100 epoch=============\n",
      "Training Loss:  0.9127627314807172 Time:  2904.539835691452 s\n",
      "Testing Loss:  1.342734134859509\n",
      "Testing Accuracy:  70.91936535535753 %\n",
      "====================\n",
      "==================17/100 epoch=============\n",
      "Training Loss:  0.8887778369345671 Time:  2903.4485199451447 s\n",
      "Testing Loss:  1.3712526328033872\n",
      "Testing Accuracy:  69.89784829384917 %\n",
      "====================\n",
      "==================18/100 epoch=============\n",
      "Training Loss:  0.8684629979236039 Time:  2904.4134562015533 s\n",
      "Testing Loss:  1.39690952665276\n",
      "Testing Accuracy:  69.26755053249293 %\n",
      "====================\n",
      "==================19/100 epoch=============\n",
      "Training Loss:  0.8533093021628197 Time:  2904.891082048416 s\n",
      "Testing Loss:  1.3640636338127985\n",
      "Testing Accuracy:  69.55009780482504 %\n",
      "====================\n",
      "==================20/100 epoch=============\n",
      "Training Loss:  0.8347434234082848 Time:  2904.476614713669 s\n",
      "Testing Loss:  1.4134113093217213\n",
      "Testing Accuracy:  69.1806129102369 %\n",
      "====================\n",
      "==================21/100 epoch=============\n",
      "Training Loss:  0.8179857320805193 Time:  2905.1706070899963 s\n",
      "Testing Loss:  1.2932437459627788\n",
      "Testing Accuracy:  71.54966311671376 %\n",
      "====================\n",
      "==================22/100 epoch=============\n",
      "Training Loss:  0.8014280938196597 Time:  2903.7436985969543 s\n",
      "Testing Loss:  1.3428000625636842\n",
      "Testing Accuracy:  70.13692675505325 %\n",
      "====================\n",
      "==================23/100 epoch=============\n",
      "Training Loss:  0.7899004715131793 Time:  2905.7602536678314 s\n",
      "Testing Loss:  1.309889511929618\n",
      "Testing Accuracy:  71.28885024994567 %\n",
      "====================\n",
      "==================24/100 epoch=============\n",
      "Training Loss:  0.7772643398980646 Time:  2905.259268760681 s\n",
      "Testing Loss:  1.252032185594241\n",
      "Testing Accuracy:  72.223429689198 %\n",
      "====================\n",
      "==================25/100 epoch=============\n",
      "Training Loss:  0.7661637770775173 Time:  2905.005800008774 s\n",
      "Testing Loss:  1.2748142629861832\n",
      "Testing Accuracy:  72.02782003912192 %\n",
      "====================\n",
      "==================26/100 epoch=============\n",
      "Training Loss:  0.7544995588557807 Time:  2905.424660921097 s\n",
      "Testing Loss:  1.2687351024813123\n",
      "Testing Accuracy:  71.24538143881765 %\n",
      "====================\n",
      "==================27/100 epoch=============\n",
      "Training Loss:  0.7452193639875572 Time:  2904.1740415096283 s\n",
      "Testing Loss:  1.3762872334983614\n",
      "Testing Accuracy:  69.78917626602913 %\n",
      "====================\n",
      "==================28/100 epoch=============\n",
      "Training Loss:  0.7352283841896695 Time:  2906.004697084427 s\n",
      "Testing Loss:  1.3063353763686285\n",
      "Testing Accuracy:  71.13670941099761 %\n",
      "====================\n",
      "==================29/100 epoch=============\n",
      "Training Loss:  0.7265451835331554 Time:  2905.598263502121 s\n",
      "Testing Loss:  1.2907390925619338\n",
      "Testing Accuracy:  71.89741360573788 %\n",
      "====================\n",
      "==================30/100 epoch=============\n",
      "Training Loss:  0.7171171260104604 Time:  2905.91819524765 s\n",
      "Testing Loss:  1.2835848099655576\n",
      "Testing Accuracy:  71.74527276678982 %\n",
      "====================\n",
      "==================31/100 epoch=============\n",
      "Training Loss:  0.7073139671287308 Time:  2907.61705827713 s\n",
      "Testing Loss:  1.2619104120466444\n",
      "Testing Accuracy:  72.245164094762 %\n",
      "====================\n",
      "==================32/100 epoch=============\n",
      "Training Loss:  0.701932167699317 Time:  2906.735645532608 s\n",
      "Testing Loss:  1.3685915701919131\n",
      "Testing Accuracy:  69.9847859161052 %\n",
      "====================\n",
      "==================33/100 epoch=============\n",
      "Training Loss:  0.6956765190611222 Time:  2911.9187693595886 s\n",
      "Testing Loss:  1.4395513435204823\n",
      "Testing Accuracy:  69.1588785046729 %\n",
      "====================\n",
      "==================34/100 epoch=============\n",
      "Training Loss:  0.6901162952152202 Time:  2954.4857873916626 s\n",
      "Testing Loss:  1.2337564941909578\n",
      "Testing Accuracy:  72.63638339491415 %\n",
      "====================\n",
      "==================35/100 epoch=============\n",
      "Training Loss:  0.6795357436609744 Time:  2941.7362775802612 s\n",
      "Testing Loss:  1.258162048127916\n",
      "Testing Accuracy:  72.85372745055423 %\n",
      "====================\n",
      "==================36/100 epoch=============\n",
      "Training Loss:  0.6742494138233726 Time:  2973.457225561142 s\n",
      "Testing Loss:  1.273851431078381\n",
      "Testing Accuracy:  71.13670941099761 %\n",
      "====================\n",
      "==================37/100 epoch=============\n",
      "Training Loss:  0.6680196640064306 Time:  2979.357411623001 s\n",
      "Testing Loss:  1.2411685668759875\n",
      "Testing Accuracy:  72.94066507281026 %\n",
      "====================\n",
      "==================38/100 epoch=============\n",
      "Training Loss:  0.6640002643561935 Time:  2993.2656145095825 s\n",
      "Testing Loss:  1.3614105814033084\n",
      "Testing Accuracy:  69.74570745490111 %\n",
      "====================\n",
      "==================39/100 epoch=============\n",
      "Training Loss:  0.6558293082042693 Time:  2988.070597887039 s\n",
      "Testing Loss:  1.3128668268521626\n",
      "Testing Accuracy:  70.98456857204955 %\n",
      "====================\n",
      "==================40/100 epoch=============\n",
      "Training Loss:  0.6534133018533772 Time:  2997.5435650348663 s\n",
      "Testing Loss:  1.2671993209256067\n",
      "Testing Accuracy:  72.37557052814606 %\n",
      "====================\n",
      "==================41/100 epoch=============\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  0.6455427852260925 Time:  3016.3839313983917 s\n",
      "Testing Loss:  1.2843398617373571\n",
      "Testing Accuracy:  72.223429689198 %\n",
      "====================\n",
      "==================42/100 epoch=============\n",
      "Training Loss:  0.6408380454784238 Time:  3026.427872657776 s\n",
      "Testing Loss:  1.271025280157725\n",
      "Testing Accuracy:  72.04955444468594 %\n",
      "====================\n",
      "==================43/100 epoch=============\n",
      "Training Loss:  0.6381099373728483 Time:  3036.6465809345245 s\n",
      "Testing Loss:  1.291968325773875\n",
      "Testing Accuracy:  71.74527276678982 %\n",
      "====================\n",
      "==================44/100 epoch=============\n",
      "Training Loss:  0.6335622104740751 Time:  3010.1208102703094 s\n",
      "Testing Loss:  1.3053388992945354\n",
      "Testing Accuracy:  71.65833514453381 %\n",
      "====================\n",
      "==================45/100 epoch=============\n",
      "Training Loss:  0.6307973560864386 Time:  3038.750501871109 s\n",
      "Testing Loss:  1.2489794724517398\n",
      "Testing Accuracy:  72.65811780047817 %\n",
      "====================\n",
      "==================46/100 epoch=============\n",
      "Training Loss:  0.6259187701579234 Time:  3026.490130662918 s\n",
      "Testing Loss:  1.2457501391569774\n",
      "Testing Accuracy:  73.17974353401434 %\n",
      "====================\n",
      "==================47/100 epoch=============\n",
      "Training Loss:  0.621947800406576 Time:  3087.880307674408 s\n",
      "Testing Loss:  1.2270137800110712\n",
      "Testing Accuracy:  72.7885242338622 %\n",
      "====================\n",
      "==================48/100 epoch=============\n",
      "Training Loss:  0.6141053080015989 Time:  3086.690610408783 s\n",
      "Testing Loss:  1.2428433100382488\n",
      "Testing Accuracy:  72.37557052814606 %\n",
      "====================\n",
      "==================49/100 epoch=============\n",
      "Training Loss:  0.6165736856688264 Time:  3036.6500310897827 s\n",
      "Testing Loss:  1.3686698840724096\n",
      "Testing Accuracy:  69.83264507715714 %\n",
      "====================\n",
      "==================50/100 epoch=============\n",
      "Training Loss:  0.6069415427424283 Time:  3022.065724849701 s\n",
      "Testing Loss:  1.3158949116865795\n",
      "Testing Accuracy:  71.72353836122582 %\n",
      "====================\n",
      "==================51/100 epoch=============\n",
      "Training Loss:  0.6096882955200162 Time:  3001.1128885746 s\n",
      "Testing Loss:  1.253716563185056\n",
      "Testing Accuracy:  72.85372745055423 %\n",
      "====================\n",
      "==================52/100 epoch=============\n",
      "Training Loss:  0.6047112156113942 Time:  2905.4264435768127 s\n",
      "Testing Loss:  1.242060701052348\n",
      "Testing Accuracy:  72.54944577265812 %\n",
      "====================\n",
      "==================53/100 epoch=============\n",
      "Training Loss:  0.6005857856306311 Time:  2905.100410223007 s\n",
      "Testing Loss:  1.2292793757385678\n",
      "Testing Accuracy:  73.02760269506628 %\n",
      "====================\n",
      "==================54/100 epoch=============\n",
      "Training Loss:  0.5957715207401194 Time:  2905.4031188488007 s\n",
      "Testing Loss:  1.230948766072591\n",
      "Testing Accuracy:  72.81025863942621 %\n",
      "====================\n",
      "==================55/100 epoch=============\n",
      "Training Loss:  0.5956416950070509 Time:  2905.1540150642395 s\n",
      "Testing Loss:  1.275201365351677\n",
      "Testing Accuracy:  71.50619430558575 %\n",
      "====================\n",
      "==================56/100 epoch=============\n",
      "Training Loss:  0.5906406056256512 Time:  2902.899399995804 s\n",
      "Testing Loss:  1.1826351152526007\n",
      "Testing Accuracy:  73.98391653988263 %\n",
      "====================\n",
      "==================57/100 epoch=============\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-2e243c7b2199>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"=================={0}/{1} epoch=============\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloaders_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mtest_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloaders_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mTrain_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-20-cc0db327dbcc>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, criterion, optimizer)\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mrunning_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/airflow/celery_airflow/airflow_env/lib/python3.5/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    312\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/airflow/celery_airflow/airflow_env/lib/python3.5/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    312\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/airflow/celery_airflow/airflow_env/lib/python3.5/site-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m             \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/airflow/celery_airflow/airflow_env/lib/python3.5/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/airflow/celery_airflow/airflow_env/lib/python3.5/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mConverted\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \"\"\"\n\u001b[0;32m---> 76\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/airflow/celery_airflow/airflow_env/lib/python3.5/site-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;31m# yikes, this transpose takes 80% of the loading time/CPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mByteTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "n_epochs = 100\n",
    "Train_loss = []\n",
    "Test_loss = []\n",
    "Test_acc = []\n",
    "for i in range(n_epochs):\n",
    "    print(\"=================={0}/{1} epoch=============\".format(i, n_epochs))\n",
    "    train_loss = train_model(model, dataloaders_dict['train'], criterion, optimizer)\n",
    "    test_loss, test_acc = test_model(model, dataloaders_dict['val'], criterion)\n",
    "    Train_loss.append(train_loss)\n",
    "    Test_loss.append(test_loss)\n",
    "    Test_acc.append(test_acc)\n",
    "    print('='*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_to_class = {val: key for key, val in image_datasets['train'].class_to_idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import pandas as pd\n",
    "from torch.autograd import Variable\n",
    "data = {\"id\": [], \"label\": []}\n",
    "data_transform = transforms.Compose([\n",
    "                #transforms.RandomResizedCrop(32),\n",
    "                transforms.ToTensor(),\n",
    "                #transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "                transforms.Normalize([0.44, 0.28, 0.37], [0.26, 0.18, 0.24])\n",
    "            ])\n",
    "for i in range(4600):\n",
    "    model.eval()\n",
    "    model.to('cuda')\n",
    "    data[\"id\"].append(i)\n",
    "    path = \"/home/d.milovanov/win_kaggle/hw3/test_classification/\" + str(i) + \".jpg\"\n",
    "    with open(path, 'rb') as f:\n",
    "        raw_image = Image.open(f)\n",
    "        img = data_transform(raw_image)\n",
    "        img = img.unsqueeze(0)\n",
    "        \n",
    "        img = Variable(img)\n",
    "        img = img.cuda()\n",
    "        outputs = model(img)\n",
    "        _, predicted = torch.max(outputs[1].data, 1)\n",
    "        data[\"label\"].append(idx_to_class[predicted.item()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.DataFrame.from_dict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv(\"sub_6.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4595</th>\n",
       "      <td>4595</td>\n",
       "      <td>1949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4596</th>\n",
       "      <td>4596</td>\n",
       "      <td>1521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4597</th>\n",
       "      <td>4597</td>\n",
       "      <td>526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4598</th>\n",
       "      <td>4598</td>\n",
       "      <td>1178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4599</th>\n",
       "      <td>4599</td>\n",
       "      <td>2110</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id label\n",
       "4595  4595  1949\n",
       "4596  4596  1521\n",
       "4597  4597   526\n",
       "4598  4598  1178\n",
       "4599  4599  2110"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_datasets_ver = {}\n",
    "dataloaders_dict_ver ={}\n",
    "data_transforms = {\n",
    "            'train': transforms.Compose([\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                #transforms.RandomResizedCrop(32),\n",
    "                transforms.ToTensor(),\n",
    "                #transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "                transforms.Normalize([0.44, 0.28, 0.37], [0.26, 0.18, 0.24])\n",
    "            ]),\n",
    "            'val': transforms.Compose([\n",
    "                #transforms.Resize(32),\n",
    "                #transforms.CenterCrop(32),\n",
    "                transforms.ToTensor(),\n",
    "                #transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "                transforms.Normalize([0.44, 0.28, 0.37], [0.26, 0.18, 0.24])\n",
    "            ]),\n",
    "        }\n",
    "image_datasets_ver['val'] = datasets.ImageFolder('/home/d.milovanov/win_kaggle/hw3/validation_verification/',\n",
    "                                             data_transforms['val'])\n",
    "\n",
    "dataloaders_dict_ver['val'] = torch.utils.data.DataLoader(image_datasets_ver['val'],batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([350])\n",
      "tensor([24])\n",
      "tensor([484])\n",
      "[[0.3494428]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "\n",
    "    running_loss = 0.0\n",
    "    total_predictions = 0.0\n",
    "    correct_predictions = 0.0\n",
    "    count = 0\n",
    "    outputs = []\n",
    "    for batch_idx, (data, target) in enumerate(dataloaders_dict_ver['val']):\n",
    "        print(target)\n",
    "        data = data.float()\n",
    "        data = data.to(device)\n",
    "        target = target.long().to(device)\n",
    "\n",
    "        outputs.append(model(data)[1])\n",
    "        \n",
    "        count += 1\n",
    "        if count > 2:\n",
    "            print(cosine_similarity(outputs[0].cpu().numpy(), outputs[1].cpu().numpy()))\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import pandas as pd\n",
    "from torch.autograd import Variable\n",
    "data = {\"id\": [], \"label\": []}\n",
    "data_transform = transforms.Compose([\n",
    "                #transforms.RandomResizedCrop(32),\n",
    "                transforms.ToTensor(),\n",
    "                #transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "                transforms.Normalize([0.44, 0.28, 0.37], [0.26, 0.18, 0.24])\n",
    "            ])\n",
    "scores_pred = []\n",
    "for i in range(sample.shape[0]):\n",
    "    if i % 100000 == 0:\n",
    "        print(i)\n",
    "    model.eval()\n",
    "    model.to('cuda')\n",
    "    path_1 = sample.iloc[i].trial.split()[0]\n",
    "    path_2 = sample.iloc[i].trial.split()[1]\n",
    "    with open(\"/home/d.milovanov/win_kaggle/hw3/test_verification/\" + path_1, 'rb') as f:\n",
    "        raw_image = Image.open(f)\n",
    "        img = data_transform(raw_image)\n",
    "        img = img.unsqueeze(0)\n",
    "        \n",
    "        img = Variable(img)\n",
    "        img = img.cuda()\n",
    "        outputs_1 = model(img)[1]\n",
    "    with open(\"/home/d.milovanov/win_kaggle/hw3/test_verification/\" + path_2, 'rb') as f:\n",
    "        raw_image = Image.open(f)\n",
    "        img = data_transform(raw_image)\n",
    "        img = img.unsqueeze(0)\n",
    "        \n",
    "        img = Variable(img)\n",
    "        img = img.cuda()\n",
    "        outputs_2 = model(img)[1]\n",
    "    #print(cosine_similarity(outputs_1.detach().cpu().numpy(), outputs_2.detach().cpu().numpy()).reshape(1))\n",
    "    scores_pred.append(cosine_similarity(outputs_1.detach().cpu().numpy(), outputs_2.detach().cpu().numpy()).reshape(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample['score'] = scores_pred\n",
    "sample.to_csv(\"ver_sub.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
